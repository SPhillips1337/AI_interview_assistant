{
    "projectName": "Interview Assistant",
    "description": "A responsive web application that acts as an interview assistant. It takes spoken or typed input, sends it to a large language model (LLM), and displays the response with full markdown formatting. Features include persistent conversation memory, topic navigation, query queuing, and comprehensive reporting capabilities.",
    "developmentStatus": "In Development",
    "technologies": {
        "frontend": ["HTML5", "CSS3", "Bootstrap 5", "jQuery", "Marked.js"],
        "backend": "PHP"
    },
    "features": [
        {
            "name": "Voice/Text Input",
            "description": "Accepts user input in a textarea on the main page.",
            "status": "Implemented"
        },
        {
            "name": "Automatic Submission (Debounced)",
            "description": "Automatically sends the input to an LLM after a short delay of inactivity.",
            "status": "Implemented"
        },
        {
            "name": "LLM Integration",
            "description": "Supports both Ollama and OpenAI as backends via a PHP proxy.",
            "status": "Implemented"
        },
        {
            "name": "Enable/Disable Toggle",
            "description": "A toggle switch to control automatic submission.",
            "status": "Implemented"
        },
        {
            "name": "Conversation History",
            "description": "A separate page (`history.php`) that displays a timeline of all conversations.",
            "status": "Implemented"
        },
        {
            "name": "Dig Deeper with Perplexica",
            "description": "Allows users to send a response to a Perplexica instance for further research.",
            "status": "Implemented"
        },
        {
            "name": "Conversational Memory",
            "description": "Remembers the context of your recent conversation with persistent localStorage storage, allowing you to ask follow-up questions naturally across browser sessions.",
            "status": "Implemented"
        },
        {
            "name": "Topic Recognition",
            "description": "Analyzes the conversation history to identify the main topic, displayed in a separate tab on the history page.",
            "status": "Implemented"
        },
        {
            "name": "Conversation Report Generation",
            "description": "Generates a downloadable HTML report summarizing the conversation, including a full transcript and identified keywords.",
            "status": "Implemented"
        },
        {
            "name": "Topic Word Cloud",
            "description": "Analyzes the entire conversation history to generate weighted topic data suitable for a word cloud visualization.",
            "status": "Implemented"
        },
        {
            "name": "Streaming LLM Responses",
            "description": "LLM responses are streamed to the user in real-time, improving perceived performance.",
            "status": "Implemented"
        },
        {
            "name": "Responsive Navbar",
            "description": "A responsive navigation bar has been added for easy navigation between the main pages.",
            "status": "Implemented"
        },
        {
            "name": "Quick Response",
            "description": "Displays a context-aware, one-paragraph summary of the user's query topic using a lightweight model, appearing before the main response with full conversation context.",
            "status": "Implemented"
        },
        {
            "name": "Markdown Response Rendering",
            "description": "All assistant responses (main responses, quick takes, current topic, and history) are rendered with markdown formatting for improved readability, including headers, lists, code blocks, and links.",
            "status": "Implemented"
        },
        {
            "name": "Query Queue System",
            "description": "Allows queuing multiple queries while processing current requests, enabling continuous conversation flow without waiting for responses.",
            "status": "Implemented"
        },
        {
            "name": "Environment Configuration Integration",
            "description": "PHP environment variables are properly loaded and passed to JavaScript for dynamic configuration.",
            "status": "Implemented"
        },
        {
            "name": "Responsive Layout Design",
            "description": "Three-column responsive layout with topic navigation sidebar, input controls, and quick response areas that adapts to different screen sizes.",
            "status": "Implemented"
        },
        {
            "name": "Topic Navigation Widget",
            "description": "Fixed sidebar widget that builds a clickable list of conversation topics with timestamps, allowing quick navigation to specific responses.",
            "status": "Implemented"
        },
        {
            "name": "Enhanced Report Generation",
            "description": "Generates comprehensive HTML reports with LLM-generated summaries, markdown-formatted responses, topic links, and proper file naming.",
            "status": "Implemented"
        }
    ],
    "futureEnhancements": [
        "Add internal navigation links within generated reports for easier browsing",
        "Persist conversation history server-side in a more robust way (e.g., SQLite)",
        "Add user-selectable models and providers via the UI",
        "Add unit tests for the PHP backend",
        "Add syntax highlighting for code blocks in markdown responses",
        "Implement conversation export/import functionality",
        "Add search functionality within conversation history"
    ],
    "fileStructure": {
        "index.php": "Main application page with a chat-style interface for asking questions and seeing a scrollable history of responses.",
        "history.php": "Page to display the conversation history and download reports.",
        "api/ask.php": "PHP proxy to handle streaming LLM requests and save history.",
        "api/quick_response.php": "PHP endpoint to generate a quick response using a lightweight model.",
        "api/history.php": "PHP endpoint to serve the conversation history.",
        "api/perplexica.php": "PHP proxy to handle Perplexica requests.",
        "api/topic.php": "PHP endpoint to analyze and return the current conversation topic.",
        "api/topics.php": "PHP endpoint that analyzes the entire history to generate weighted topic data for a word cloud.",
        "api/generate_report.php": "PHP endpoint to generate and download a full conversation report in HTML format.",
        "assets/js/app.js": "JavaScript for the main application page, including handling of streaming responses.",
        "assets/js/history.js": "JavaScript for the history page.",
        "assets/css/style.css": "Custom CSS styles.",
        ".env.example": "Example environment variables file.",
        "README.md": "Project documentation.",
        "PLAN.md": "Initial project plan.",
        "project.json": "This file, providing a structured overview of the project."
    }
}
